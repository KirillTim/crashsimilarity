{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from datetime import timedelta\n",
    "from crashsimilarity.downloader import SocorroDownloader\n",
    "from crashsimilarity import utils\n",
    "from crashsimilarity.distance import DistanceCalculator\n",
    "from gensim.models import doc2vec\n",
    "import crashsimilarity.tmp as tmp\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signature1 = 'mozilla::net::nsHttpConnection::CloseConnectionFastOpenTakesTooLongOrError'\n",
    "signature2 = 'OOM | large | js::AutoEnterOOMUnsafeRegion::crash | js::AutoEnterOOMUnsafeRegion::crash | js::TenuringTracer::moveToTenured'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_stack_traces(sigs, traces_num=1):\n",
    "    from_date = utils.utc_today() - timedelta(days=360)\n",
    "    if isinstance(sigs, str):\n",
    "        sigs = [sigs]\n",
    "    params = {'signature': ['^'+i for i in sigs],\n",
    "              'date': ['>=' + str(from_date)],\n",
    "              '_facets': ['proto_signature'],\n",
    "              '_facets_size': traces_num\n",
    "             }\n",
    "    _SUPER_SEARCH_URL = 'https://crash-stats.mozilla.com/api/SuperSearch'\n",
    "    r = requests.get(_SUPER_SEARCH_URL, params)\n",
    "    return r.json()['facets']['proto_signature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# traces1 = download_stack_traces(signature1, traces_num=1000)\n",
    "traces2 = download_stack_traces(signature2, traces_num=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traces2 = download_stack_traces(signature2, traces_num=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traces2 = set([i['term'] for i in traces2])\n",
    "corpus = []\n",
    "for x in traces2:\n",
    "    words = utils.StackTraceProcessor.preprocess(x)\n",
    "    if words[0] == '@0x':\n",
    "        words = words[1:]\n",
    "    corpus.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222895"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = pickle.load(open('data/compressed_vocab.pickle', 'rb'))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compressed_corpus = [[str(vocab.get(i, i)) for i in c] for c in corpus]\n",
    "compressed_corpus = [doc2vec.TaggedDocument(trace, [i]) for i, trace in enumerate(compressed_corpus)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edit_distance(s1, s2, dist):\n",
    "    if len(s1) < len(s2):\n",
    "        return edit_distance(s2, s1, dist)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            d = [dist(s1[i], s2[j]), #insert\n",
    "                 dist(s2[j], s2[j-1]), #del\n",
    "                 dist(c1, c2)] #subst\n",
    "            d = [2 if i < 0 else i for i in d]\n",
    "            insertions = previous_row[j + 1] + d[0]\n",
    "            deletions = current_row[j] + d[1]      \n",
    "            substitutions = previous_row[j] + (c1 != c2) * d[2]\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def edit_distance_matrix(corpus, calculator, prog=10):\n",
    "    dist = np.zeros((len(corpus), len(corpus)), dtype=np.double)\n",
    "    idx = []\n",
    "    for i in range(len(corpus)):\n",
    "        for j in range(i+1, len(corpus)):\n",
    "            idx.append((i, j))\n",
    "    say = len(idx) // prog\n",
    "    t = time.time()\n",
    "    for s, (i, j) in enumerate(idx):\n",
    "        if s and s % say == 0:\n",
    "            print('{}%, {} s.'.format(s / (len(idx) * 0.01), time.time() - t))\n",
    "        doc1 = corpus[i].words\n",
    "        doc2 = corpus[j].words\n",
    "        dist[i, j] = dist[j, i] = calculator(doc1, doc2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def calculator(s1, s2):\n",
    "#     return edit_distance(s1, s2, lambda a, b: 1)\n",
    "# no_coff_edit_dist_mat = edit_distance_matrix(compressed_corpus, calculator)\n",
    "# pickle.dump(no_coff_edit_dist_mat, open('data/silhouette_one_signature/sig_2_edit_no_coff.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading Doc2Vec object from data/model/dm_d200_all.model\n",
      "INFO:gensim.utils:loading wv recursively from data/model/dm_d200_all.model.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading syn0 from data/model/dm_d200_all.model.wv.syn0.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute syn0norm to None\n",
      "INFO:gensim.utils:loading docvecs recursively from data/model/dm_d200_all.model.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loading doctag_syn0 from data/model/dm_d200_all.model.docvecs.doctag_syn0.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn1neg from data/model/dm_d200_all.model.syn1neg.npy with mmap=None\n",
      "INFO:gensim.utils:setting ignored attribute cum_table to None\n",
      "INFO:gensim.utils:loaded data/model/dm_d200_all.model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.doc2vec.Doc2Vec at 0x7efbdcd5fd30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = doc2vec.Doc2Vec.load('data/model/dm_d200_all.model')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.keyedvectors:precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(words) = 681\n"
     ]
    }
   ],
   "source": [
    "dist, w2pos =  DistanceCalculator.words_distance(compressed_corpus, model)\n",
    "distance_calculator = DistanceCalculator(model, w2pos, dist)\n",
    "pos2w = dict([(i[1], i[0]) for i in w2pos.items()])\n",
    "pos2vocab = dict([(i[1], i[0]) for i in vocab.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def my_edit_distance(s1, s2):\n",
    "#     return edit_distance(s1, s2, distance_calculator.compressed_words_dist)\n",
    "# coff_edit_dist_mat = edit_distance_matrix(compressed_corpus, my_edit_distance)\n",
    "# pickle.dump(coff_edit_dist_mat, open('data/silhouette_one_signature/sig_2_edit_coff.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coff_edit_dist_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25065416365025067"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "\n",
    "db = DBSCAN(eps = 5, min_samples=5, metric='precomputed').fit(coff_edit_dist_mat)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "metrics.silhouette_score(coff_edit_dist_mat, labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12032512438051259"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db2 = DBSCAN(eps = 5, min_samples=3, metric='precomputed').fit(no_coff_edit_dist_mat)\n",
    "labels2 = db2.labels_\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters2_ = len(set(labels2)) - (1 if -1 in labels2 else 0)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters2_)\n",
    "metrics.silhouette_score(no_coff_edit_dist_mat, labels2, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wmd_mat(corpus, calculator, prog=10):\n",
    "    wmd_dist = np.zeros((len(corpus), len(corpus)), dtype=np.double)\n",
    "    idx = []\n",
    "    for i in range(len(corpus)):\n",
    "        for j in range(i+1, len(corpus)):\n",
    "            idx.append((i, j))\n",
    "    say = len(idx) // prog\n",
    "    t = time.time()\n",
    "    for s, (i, j) in enumerate(idx):\n",
    "        if s and s % say == 0:\n",
    "            print('{}%, {} s.'.format(s / (len(idx) * 0.01), time.time() - t))\n",
    "        doc1 = corpus[i].words\n",
    "        doc2 = corpus[j].words\n",
    "        wmd_dist[i, j] = wmd_dist[j, i] = calculator.fast_wmd(doc1, doc2)\n",
    "    return wmd_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0%, 66.15560245513916 s.\n",
      "20.0%, 127.54200649261475 s.\n",
      "30.0%, 198.4199869632721 s.\n",
      "40.0%, 260.1379313468933 s.\n",
      "50.0%, 322.2272343635559 s.\n",
      "60.0%, 381.7083694934845 s.\n",
      "70.0%, 445.0794062614441 s.\n",
      "80.0%, 507.2526469230652 s.\n",
      "90.0%, 574.6762454509735 s.\n"
     ]
    }
   ],
   "source": [
    "wmd_dist_mat = wmd_mat(compressed_corpus, distance_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.026525818282212354"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db3 = DBSCAN(min_samples=5, metric='precomputed').fit(wmd_dist_mat)\n",
    "labels3 = db3.labels_\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters3_ = len(set(labels3)) - (1 if -1 in labels3 else 0)\n",
    "\n",
    "print('Estimated number of clusters: %d' % n_clusters3_)\n",
    "metrics.silhouette_score(no_coff_edit_dist_mat, labels3, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52704627669472992"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_true = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "labels_pred = [0, 0, 1, 1, 1, 2, 2, 2, 2]\n",
    "metrics.fowlkes_mallows_score(labels_true, labels_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
